#include <iostream>
#include <chrono>
#include <thread>
#include <vector>
#include <atomic>
#include <random>
#include <iomanip>
#include <fstream>
#include <sstream>
#include <numeric>
#include <algorithm>
#include <json/json.h>
#include "client.h"
#include "task.pb.h"

// æ€§èƒ½æµ‹è¯•ç»“æœç»“æ„
struct PerformanceResult {
    std::string test_name;
    int64_t total_time_ms;
    int64_t avg_time_ms;
    int64_t min_time_ms;
    int64_t max_time_ms;
    int64_t total_operations;
    double throughput;  // æ“ä½œ/ç§’
    double success_rate;
    std::string description;
};

// æ€§èƒ½æµ‹è¯•ç±»
class PerformanceTest {
private:
    std::vector<PerformanceResult> results_;
    std::atomic<int64_t> total_tasks_submitted_{0};
    std::atomic<int64_t> total_tasks_completed_{0};
    std::atomic<int64_t> total_tasks_failed_{0};
    
    // ç”Ÿæˆéšæœºä»»åŠ¡ID
    std::string generate_task_id() {
        static std::random_device rd;
        static std::mt19937 gen(rd());
        static std::uniform_int_distribution<> dis(1000, 9999);
        return "perf-test-" + std::to_string(dis(gen));
    }
    
    // åˆ›å»ºæµ‹è¯•ä»»åŠ¡
    taskscheduler::Task create_test_task(const std::string& task_type = "simple") {
        taskscheduler::Task task;
        task.set_task_id(generate_task_id());
        task.set_type(taskscheduler::FUNCTION);  // ä½¿ç”¨å‡½æ•°ç±»å‹
        
        // è®¾ç½®ä»»åŠ¡å†…å®¹
        std::string content;
        if (task_type == "cpu_intensive") {
            content = "cpu_bound_function";
        } else if (task_type == "memory_intensive") {
            content = "memory_bound_function";
        } else if (task_type == "io_intensive") {
            content = "io_bound_function";
        } else {
            content = "simple_function";
        }
        task.set_content(content);
        
        // è®¾ç½®ä»»åŠ¡å‚æ•°åˆ°metadata
        if (task_type == "cpu_intensive") {
            task.mutable_metadata()->insert({"iterations", "1000000"});
            task.mutable_metadata()->insert({"operation", "cpu_bound"});
        } else if (task_type == "memory_intensive") {
            task.mutable_metadata()->insert({"size_mb", "100"});
            task.mutable_metadata()->insert({"operation", "memory_bound"});
        } else if (task_type == "io_intensive") {
            task.mutable_metadata()->insert({"file_size", "10"});
            task.mutable_metadata()->insert({"operation", "io_bound"});
        } else {
            task.mutable_metadata()->insert({"iterations", "1000"});
            task.mutable_metadata()->insert({"operation", "simple"});
        }
        
        return task;
    }

public:
    // ä»»åŠ¡æäº¤æ€§èƒ½æµ‹è¯•
    PerformanceResult test_task_submission_performance(int task_count = 1000) {
        std::cout << "\n=== ä»»åŠ¡æäº¤æ€§èƒ½æµ‹è¯• ===" << std::endl;
        std::cout << "æµ‹è¯•ä»»åŠ¡æ•°é‡: " << task_count << std::endl;
        
        Client client;
        client.start();
        
        std::vector<int64_t> submission_times;
        submission_times.reserve(task_count);
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        for (int i = 0; i < task_count; ++i) {
            auto task_start = std::chrono::high_resolution_clock::now();
            
            taskscheduler::Task task = create_test_task("simple");
            client.submit_one_task(task);
            
            auto task_end = std::chrono::high_resolution_clock::now();
            auto duration = std::chrono::duration_cast<std::chrono::microseconds>(task_end - task_start);
            submission_times.push_back(duration.count());
            
            total_tasks_submitted_++;
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        auto total_duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
        
        // è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        int64_t total_time = total_duration.count();
        int64_t avg_time = std::accumulate(submission_times.begin(), submission_times.end(), 0LL) / submission_times.size();
        int64_t min_time = *std::min_element(submission_times.begin(), submission_times.end());
        int64_t max_time = *std::max_element(submission_times.begin(), submission_times.end());
        double throughput = (task_count * 1000.0) / total_time;  // ä»»åŠ¡/ç§’
        
        PerformanceResult result{
            "ä»»åŠ¡æäº¤æ€§èƒ½æµ‹è¯•",
            total_time,
            avg_time,
            min_time,
            max_time,
            task_count,
            throughput,
            100.0,  // å‡è®¾100%æˆåŠŸç‡
            "æµ‹è¯•ä»»åŠ¡æäº¤çš„ååé‡å’Œå»¶è¿Ÿ"
        };
        
        results_.push_back(result);
        print_result(result);
        
        client.stop();
        return result;
    }
    
    // å¹¶å‘ä»»åŠ¡å¤„ç†æ€§èƒ½æµ‹è¯•
    PerformanceResult test_concurrent_task_processing(int concurrent_tasks = 100, int threads = 4) {
        std::cout << "\n=== å¹¶å‘ä»»åŠ¡å¤„ç†æ€§èƒ½æµ‹è¯• ===" << std::endl;
        std::cout << "å¹¶å‘ä»»åŠ¡æ•°: " << concurrent_tasks << ", çº¿ç¨‹æ•°: " << threads << std::endl;
        
        Client client;
        client.start();
        
        std::atomic<int> completed_tasks{0};
        std::atomic<int> failed_tasks{0};
        std::vector<std::thread> worker_threads;
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // åˆ›å»ºå·¥ä½œçº¿ç¨‹
        for (int t = 0; t < threads; ++t) {
            worker_threads.emplace_back([&, t]() {
                int tasks_per_thread = concurrent_tasks / threads;
                for (int i = 0; i < tasks_per_thread; ++i) {
                    try {
                        taskscheduler::Task task = create_test_task("simple");
                        client.submit_one_task(task);
                        completed_tasks++;
                    } catch (const std::exception& e) {
                        failed_tasks++;
                    }
                }
            });
        }
        
        // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for (auto& thread : worker_threads) {
            thread.join();
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        auto total_duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
        
        int64_t total_time = total_duration.count();
        double throughput = (completed_tasks * 1000.0) / total_time;
        double success_rate = (completed_tasks * 100.0) / (completed_tasks + failed_tasks);
        
        PerformanceResult result{
            "å¹¶å‘ä»»åŠ¡å¤„ç†æ€§èƒ½æµ‹è¯•",
            total_time,
            total_time / completed_tasks,
            0,  // ç®€åŒ–å¤„ç†
            0,  // ç®€åŒ–å¤„ç†
            completed_tasks,
            throughput,
            success_rate,
            "æµ‹è¯•å¤šçº¿ç¨‹å¹¶å‘æäº¤ä»»åŠ¡çš„æ€§èƒ½"
        };
        
        results_.push_back(result);
        print_result(result);
        
        client.stop();
        return result;
    }
    
    // è´Ÿè½½å‡è¡¡æ€§èƒ½æµ‹è¯•
    PerformanceResult test_load_balancing_performance(int test_rounds = 100) {
        std::cout << "\n=== è´Ÿè½½å‡è¡¡æ€§èƒ½æµ‹è¯• ===" << std::endl;
        std::cout << "æµ‹è¯•è½®æ•°: " << test_rounds << std::endl;
        
        Client client;
        client.start();
        
        std::vector<int64_t> selection_times;
        selection_times.reserve(test_rounds);
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        for (int i = 0; i < test_rounds; ++i) {
            auto selection_start = std::chrono::high_resolution_clock::now();
            
            try {
                auto scheduler_node = client.get_hearly_secheduler_node();
                auto selection_end = std::chrono::high_resolution_clock::now();
                auto duration = std::chrono::duration_cast<std::chrono::microseconds>(selection_end - selection_start);
                selection_times.push_back(duration.count());
            } catch (const std::exception& e) {
                std::cerr << "è´Ÿè½½å‡è¡¡é€‰æ‹©å¤±è´¥: " << e.what() << std::endl;
            }
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        auto total_duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
        
        int64_t total_time = total_duration.count();
        int64_t avg_time = std::accumulate(selection_times.begin(), selection_times.end(), 0LL) / selection_times.size();
        int64_t min_time = *std::min_element(selection_times.begin(), selection_times.end());
        int64_t max_time = *std::max_element(selection_times.begin(), selection_times.end());
        double throughput = (test_rounds * 1000.0) / total_time;
        
        PerformanceResult result{
            "è´Ÿè½½å‡è¡¡æ€§èƒ½æµ‹è¯•",
            total_time,
            avg_time,
            min_time,
            max_time,
            test_rounds,
            throughput,
            100.0,
            "æµ‹è¯•è´Ÿè½½å‡è¡¡ç®—æ³•çš„é€‰æ‹©æ€§èƒ½"
        };
        
        results_.push_back(result);
        print_result(result);
        
        client.stop();
        return result;
    }
    
    // ä»»åŠ¡æ‰§è¡Œæ€§èƒ½æµ‹è¯•
    PerformanceResult test_task_execution_performance(int task_count = 100) {
        std::cout << "\n=== ä»»åŠ¡æ‰§è¡Œæ€§èƒ½æµ‹è¯• ===" << std::endl;
        std::cout << "æµ‹è¯•ä»»åŠ¡æ•°é‡: " << task_count << std::endl;
        
        Client client;
        client.start();
        
        std::vector<taskscheduler::Task> tasks;
        std::vector<std::string> task_ids;
        
        // æäº¤ä»»åŠ¡
        for (int i = 0; i < task_count; ++i) {
            taskscheduler::Task task = create_test_task("cpu_intensive");
            client.submit_one_task(task);
            task_ids.push_back(task.task_id());
        }
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // ç­‰å¾…ä»»åŠ¡å®Œæˆ
        int completed_count = 0;
        int timeout_count = 0;
        const int timeout_seconds = 60;
        
        auto timeout_start = std::chrono::high_resolution_clock::now();
        
        while (completed_count < task_count) {
            for (const auto& task_id : task_ids) {
                try {
                    auto result = client.get_task_result(task_id);
                    if (!result.task_id().empty()) {
                        completed_count++;
                    }
                } catch (const std::exception& e) {
                    // ä»»åŠ¡è¿˜åœ¨æ‰§è¡Œä¸­
                }
            }
            
            auto current_time = std::chrono::high_resolution_clock::now();
            auto elapsed = std::chrono::duration_cast<std::chrono::seconds>(current_time - timeout_start);
            
            if (elapsed.count() > timeout_seconds) {
                timeout_count = task_count - completed_count;
                break;
            }
            
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        auto total_duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
        
        int64_t total_time = total_duration.count();
        double throughput = (completed_count * 1000.0) / total_time;
        double success_rate = (completed_count * 100.0) / task_count;
        
        PerformanceResult result{
            "ä»»åŠ¡æ‰§è¡Œæ€§èƒ½æµ‹è¯•",
            total_time,
            total_time / completed_count,
            0,
            0,
            completed_count,
            throughput,
            success_rate,
            "æµ‹è¯•ä»»åŠ¡ä»æäº¤åˆ°å®Œæˆçš„ç«¯åˆ°ç«¯æ€§èƒ½"
        };
        
        results_.push_back(result);
        print_result(result);
        
        client.stop();
        return result;
    }
    
    // å†…å­˜ä½¿ç”¨æ€§èƒ½æµ‹è¯•
    PerformanceResult test_memory_usage_performance(int task_count = 50) {
        std::cout << "\n=== å†…å­˜ä½¿ç”¨æ€§èƒ½æµ‹è¯• ===" << std::endl;
        std::cout << "æµ‹è¯•ä»»åŠ¡æ•°é‡: " << task_count << std::endl;
        
        Client client;
        client.start();
        
        std::vector<taskscheduler::Task> tasks;
        
        // æäº¤å†…å­˜å¯†é›†å‹ä»»åŠ¡
        for (int i = 0; i < task_count; ++i) {
            taskscheduler::Task task = create_test_task("memory_intensive");
            client.submit_one_task(task);
            tasks.push_back(task);
        }
        
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // ç­‰å¾…ä»»åŠ¡å®Œæˆ
        int completed_count = 0;
        const int timeout_seconds = 120;
        
        auto timeout_start = std::chrono::high_resolution_clock::now();
        
        while (completed_count < task_count) {
            for (const auto& task : tasks) {
                try {
                    auto result = client.get_task_result(task.task_id());
                    if (!result.task_id().empty()) {
                        completed_count++;
                    }
                } catch (const std::exception& e) {
                    // ä»»åŠ¡è¿˜åœ¨æ‰§è¡Œä¸­
                }
            }
            
            auto current_time = std::chrono::high_resolution_clock::now();
            auto elapsed = std::chrono::duration_cast<std::chrono::seconds>(current_time - timeout_start);
            
            if (elapsed.count() > timeout_seconds) {
                break;
            }
            
            std::this_thread::sleep_for(std::chrono::milliseconds(200));
        }
        
        auto end_time = std::chrono::high_resolution_clock::now();
        auto total_duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
        
        int64_t total_time = total_duration.count();
        double throughput = (completed_count * 1000.0) / total_time;
        double success_rate = (completed_count * 100.0) / task_count;
        
        PerformanceResult result{
            "å†…å­˜ä½¿ç”¨æ€§èƒ½æµ‹è¯•",
            total_time,
            total_time / completed_count,
            0,
            0,
            completed_count,
            throughput,
            success_rate,
            "æµ‹è¯•å†…å­˜å¯†é›†å‹ä»»åŠ¡çš„æ‰§è¡Œæ€§èƒ½"
        };
        
        results_.push_back(result);
        print_result(result);
        
        client.stop();
        return result;
    }
    
    // æ‰“å°æµ‹è¯•ç»“æœ
    void print_result(const PerformanceResult& result) {
        std::cout << "\nğŸ“Š " << result.test_name << std::endl;
        std::cout << "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" << std::endl;
        std::cout << "æ€»è€—æ—¶: " << result.total_time_ms << " ms" << std::endl;
        std::cout << "å¹³å‡è€—æ—¶: " << result.avg_time_ms << " Î¼s" << std::endl;
        std::cout << "æœ€å°è€—æ—¶: " << result.min_time_ms << " Î¼s" << std::endl;
        std::cout << "æœ€å¤§è€—æ—¶: " << result.max_time_ms << " Î¼s" << std::endl;
        std::cout << "æ€»æ“ä½œæ•°: " << result.total_operations << std::endl;
        std::cout << "ååé‡: " << std::fixed << std::setprecision(2) << result.throughput << " ops/s" << std::endl;
        std::cout << "æˆåŠŸç‡: " << std::fixed << std::setprecision(2) << result.success_rate << "%" << std::endl;
        std::cout << "æè¿°: " << result.description << std::endl;
        std::cout << "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" << std::endl;
    }
    
    // ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š
    void generate_report(const std::string& filename = "performance_report.txt") {
        std::ofstream report(filename);
        if (!report.is_open()) {
            std::cerr << "æ— æ³•åˆ›å»ºæŠ¥å‘Šæ–‡ä»¶: " << filename << std::endl;
            return;
        }
        
        report << "TaskHive ç³»ç»Ÿæ€§èƒ½æµ‹è¯•æŠ¥å‘Š" << std::endl;
        report << "ç”Ÿæˆæ—¶é—´: " << std::chrono::system_clock::now().time_since_epoch().count() << std::endl;
        report << "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" << std::endl;
        
        for (const auto& result : results_) {
            report << "\nğŸ“Š " << result.test_name << std::endl;
            report << "æ€»è€—æ—¶: " << result.total_time_ms << " ms" << std::endl;
            report << "å¹³å‡è€—æ—¶: " << result.avg_time_ms << " Î¼s" << std::endl;
            report << "ååé‡: " << std::fixed << std::setprecision(2) << result.throughput << " ops/s" << std::endl;
            report << "æˆåŠŸç‡: " << std::fixed << std::setprecision(2) << result.success_rate << "%" << std::endl;
            report << "æè¿°: " << result.description << std::endl;
            report << "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" << std::endl;
        }
        
        report.close();
        std::cout << "\nğŸ“„ æ€§èƒ½æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: " << filename << std::endl;
    }
    
    // è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•
    void run_all_tests() {
        std::cout << "ğŸš€ å¼€å§‹TaskHiveç³»ç»Ÿæ€§èƒ½æµ‹è¯•" << std::endl;
        std::cout << "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”" << std::endl;
        
        // è¿è¡Œå„ç§æ€§èƒ½æµ‹è¯•
        test_task_submission_performance(1000);
        test_concurrent_task_processing(500, 4);
        test_load_balancing_performance(200);
        test_task_execution_performance(50);
        test_memory_usage_performance(20);
        
        // ç”ŸæˆæŠ¥å‘Š
        generate_report();
        
        std::cout << "\nâœ… æ‰€æœ‰æ€§èƒ½æµ‹è¯•å®Œæˆ!" << std::endl;
    }
};

int main() {
    try {
        PerformanceTest test;
        test.run_all_tests();
    } catch (const std::exception& e) {
        std::cerr << "æ€§èƒ½æµ‹è¯•å¤±è´¥: " << e.what() << std::endl;
        return 1;
    }
    
    return 0;
} 